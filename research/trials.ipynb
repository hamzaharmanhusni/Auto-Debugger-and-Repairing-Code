{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\project-ruang-guru\\\\Debugging\\\\Code\\\\Custom-Debugging-Code\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file test_repo already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir test_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\"\n",
    "\n",
    "# Repo.clone_from(\"https://github.com/entbappy/End-to-end-ML-Project-Implementation\", to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(repo_path,\n",
    "                                        glob = \"**/*\",\n",
    "                                       suffixes=[\".py\"],\n",
    "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='import json\\nimport logging\\n\\nimport urllib3\\nfrom fastapi import Header\\nfrom ds_chatbot.config import AUTH_CONFIG\\nfrom dataclasses import dataclass\\nfrom ds_chatbot.config import SECRET_CONFIG\\n\\n\\nlogging.captureWarnings(True)\\nlogger = logging.getLogger(__name__)\\n\\nhttp = urllib3.HTTPConnectionPool(\\n    AUTH_CONFIG.HOST,\\n    maxsize=AUTH_CONFIG.HTTP_CONNECTION_POOL_SIZE,\\n    headers=urllib3.make_headers(keep_alive=True, accept_encoding=True),\\n)\\n\\n\\nclass AuthException(Exception):\\n    def __init__(self, message: str):\\n        self.message = message\\n\\n\\n@dataclass\\nclass Context:\\n    user_role: str\\n    user_code: str\\n\\n\\nclass Authenticate:\\n    def __init__(self, allowed_roles: list = None):\\n        self.allowed_roles = allowed_roles\\n\\n    def __call__(self, authorization: str = Header(None), user_role: str = Header(None), user_code: str = Header(None), internal_api_password: str = Header(None)):\\n        if AUTH_CONFIG.AUTHENTICATION_ACTIVE is False:\\n            return Context(user_role=\"admin\", user_code=\"admin\")\\n\\n        if user_role is not None and user_code is not None and internal_api_password is not None:\\n            # authenticating with internal api password\\n            # this is used for internal api calls and for testing\\n            return self.validate_password(user_role, user_code, internal_api_password)\\n        else:\\n            # authenticating with token\\n            # this is used for external api calls\\n            return self.validate_token(authorization)\\n\\n    def validate_password(self, user_role: str, user_code: str, internal_api_password: str) -> Context:\\n        # check if role is allowed to access this resource\\n        self.is_role_allowed(user_role)\\n\\n        if internal_api_password != SECRET_CONFIG.INTERNAL_API_PASSWORD:\\n            raise AuthException(message=\"internal api password is not valid\")\\n\\n        return Context(user_role=user_role, user_code=user_code)\\n\\n    def validate_token(self, token: str) -> Context:\\n        if token is None:\\n            raise AuthException(message=\"authorization header is missing\")\\n\\n        try:\\n            response = http.request_encode_body(\\n                \"POST\", AUTH_CONFIG.PATH, fields={\"token\": token}\\n            )\\n        except Exception as e:\\n            raise\\n\\n        data = json.loads(response.data.decode(\"utf-8\"))\\n        if response.status != 200:\\n            raise AuthException(\\n                message=f\"{data.get(\\'message\\')}, {data.get(\\'detail\\')}\")\\n\\n        role = data.get(\"data\")[0].get(\"role\")\\n        user_code = data.get(\"data\")[0].get(\"user_code\")\\n\\n        # check if role is allowed to access this resource\\n        self.is_role_allowed(role)\\n\\n        return Context(user_role=role, user_code=user_code)\\n\\n    def is_role_allowed(self, role: str):\\n        if self.allowed_roles is not None and role not in self.allowed_roles:\\n            raise AuthException(\\n                message=f\"role {role} is not allowed to access this resource\")\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\auth.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from ds_chatbot.client.openai.gpt_client import GPTClient\\nfrom ds_chatbot.client.event_tracking.api import EventTrackingApi\\nfrom ds_chatbot.client.timescale_tracking.api import TimescaleTrackingApi\\nfrom ds_chatbot.client.rg_llm.client import RgLLM\\nfrom ds_chatbot.api.routers.persona import db_conn\\n\\nfrom ds_chatbot.client.openai.prompt_gen import PromptChatGPT\\nfrom ds_chatbot.core.llm.llm_connector import LLMConnector\\nfrom ds_chatbot.core.llm.rg_llm_connector import RgLLMConnector\\n\\nfrom ds_chatbot.core.service.dto import LearningBotRequest\\nfrom ds_chatbot.core.service.chatbot_agent import ChatbotAgent\\nfrom ds_chatbot.core.service.chatgpt_discovery import ChatGPTDiscovery\\nfrom ds_chatbot.core.service.doraemon import DoraemonBot\\nfrom ds_chatbot.core.service.salesbot import SalesBotService\\nfrom ds_chatbot.core.service.learning_bot import LearningBotService\\nfrom ds_chatbot.core.service.onboarding_doraemon import OnboardingDoraemonBot\\nfrom ds_chatbot.core.doraemon.intent_embedding import IntentEmbedding\\nfrom ds_chatbot.repository.intent_classification import IntentClassificationRepository\\nfrom ds_chatbot.repository.persona import PersonaRepository\\nfrom ds_chatbot.repository.chat_history import ChatHistoryRepository, DummyChatHistoryRepository\\nfrom ds_chatbot.repository.doraemon.state_cache_repository import StateCacheRepository\\nfrom ds_chatbot.repository.doraemon.general_cache_repository import GeneralCacheRepository\\nfrom ds_chatbot.repository.redis.redis_repo import RedisRepository\\nfrom ds_chatbot.repository.redis.request_duplicate_checker import DuplicateRequestChecker\\nfrom ds_chatbot.core.general_function.general import GeneralFunction\\nfrom ds_chatbot.core.general_function.dummy_general import DummyGeneralFunction\\nfrom ds_chatbot.client.rg_balance.client import RgBalanceAPI\\nfrom ds_chatbot.core.service.middleware_feature_limit import MiddlewareFeatureLimit\\nfrom ds_chatbot.core.service.dora_balance_middleware import DoraBalanceMiddleWare\\nfrom ds_chatbot.core.service.publisher import MessagePublisher\\nfrom ds_chatbot.core.service.bot_universal import BotUniversalService\\n\\nfrom redis import Redis\\nfrom ds_chatbot.config import (\\n    REDIS_CONFIG,\\n    PUBSUB_CONFIG,\\n    MYSQL_CHAT_HISTORY_CONFIG,\\n    ES_VECTOR_DB_CONFIG,\\n    RG_LLM_CONFIG\\n)\\nfrom ds_chatbot.client.semantic_kernel.utils import load_sk, load_sk_with_dummy_completion, load_custom_sk\\nfrom ds_chatbot.core.experiment.openai_allocation import OpenAIAllocation\\n\\nfrom ds_chatbot.shared.repository import get_db_conn\\nfrom ds_chatbot.client.pubsub.client import PubsubClient\\nfrom ds_chatbot.client.pubsub.dummy_client import DummyPubsubClient\\nfrom ds_chatbot.core.service.sk_skill_update import SKSkillUpdateService\\n\\nfrom ds_chatbot.core.salesbot.memory_salesbot import MemorySalesbot\\nfrom ds_chatbot.core.salesbot.config import MEMORY_SALESBOT_CONFIG\\nfrom ds_chatbot.bot_collections.rule_based_bot.core.service.memory_rule_bot import MemoryRuleBot\\nfrom ds_chatbot.bot_collections.rule_based_bot.config import MEMORY_RULE_BOT_CONFIG\\nfrom ds_chatbot.bot_collections.rule_based_bot.core.service.rule_based_bot import RuleBaseBotService\\n\\n\\n# init redis connection\\nredis_conn = Redis(\\n    host=REDIS_CONFIG.HOST,\\n    port=REDIS_CONFIG.PORT,\\n    db=REDIS_CONFIG.DB,\\n)\\n\\nredis_repo = RedisRepository(redis_conn)\\nmemory_salesbot = MemorySalesbot(redis_conn=redis_conn, config=MEMORY_SALESBOT_CONFIG)\\nmemory_rule_base_bot = MemoryRuleBot(redis_conn=redis_conn, config=MEMORY_RULE_BOT_CONFIG)\\ndb_chat_history_conn = get_db_conn(MYSQL_CHAT_HISTORY_CONFIG)\\n\\npubsub = PubsubClient(config=PUBSUB_CONFIG)\\nchat_history_repo = ChatHistoryRepository(db_chat_history_conn)\\nmessage_publisher = MessagePublisher(pubsub_client=pubsub, chat_history_repo=chat_history_repo)\\n\\n\\n# Dummy pubsub and dummy Mysql DB\\nconfig_pubsub = PUBSUB_CONFIG.model_copy()\\nconfig_pubsub.TOPIC_NAME = config_pubsub.LOADTEST_TOPIC_NAME\\npubsub_dummy = DummyPubsubClient(config=config_pubsub)\\nchat_history_repo_dummy = DummyChatHistoryRepository(db_chat_history_conn)\\nmessage_publisher_dummy = MessagePublisher(\\n    pubsub_client=pubsub_dummy,\\n    chat_history_repo=chat_history_repo_dummy\\n)\\n\\npersona_repository = PersonaRepository(db_conn)\\nmessage_duplicate_checker = DuplicateRequestChecker(redis_repo=redis_repo)\\n\\nopenai_allocation = OpenAIAllocation()\\n\\nevent_tracker = EventTrackingApi()\\ntimescale_tracker = TimescaleTrackingApi()\\ngpt_client = GPTClient(allocation=openai_allocation)\\nrg_llm = RgLLM()\\n\\nchatgpt_prompt = PromptChatGPT()\\nif RG_LLM_CONFIG.SEMANTIC_KERNEL_ACTIVE:\\n    sk_client = load_custom_sk(\\n        cache_repo=GeneralCacheRepository(redis_conn=redis_conn)\\n    )\\nelse:\\n    sk_client = load_sk(\\n        cache_repo=GeneralCacheRepository(redis_conn=redis_conn)\\n    )\\n\\nsk_client.add_skill(\"DoraemonSkill\")\\nsk_client.add_skill(\"DoraCoreExpSkill\")\\n\\n\\n# Dummy sk_client\\nsk_client_dummy = load_sk_with_dummy_completion(\\n    cache_repo=GeneralCacheRepository(redis_conn=redis_conn)\\n)\\nsk_client_dummy.add_skill(\"DoraemonSkill\")\\n\\n\\nllm_connector = LLMConnector(\\n    model=gpt_client,\\n    event_tracker=event_tracker,\\n    cache_repo=GeneralCacheRepository(redis_conn=redis_conn)\\n)\\n\\nrg_llm_connector = RgLLMConnector(\\n    model=rg_llm,\\n    event_tracker=event_tracker,\\n    cache_repo=GeneralCacheRepository(redis_conn=redis_conn)\\n)\\n\\nif RG_LLM_CONFIG.CONNECTOR_ACTIVE:\\n    llm_connector = rg_llm_connector\\nelse:\\n    llm_connector = llm_connector\\n\\nchatbot_discovery = ChatGPTDiscovery(\\n    prompt_builder=chatgpt_prompt,\\n    event_tracker=event_tracker,\\n    persona_repository=persona_repository,\\n    llm=llm_connector,\\n    timescale_tracker=timescale_tracker\\n)\\n\\nsalesbot_service = SalesBotService(\\n    prompt_builder=chatgpt_prompt,\\n    event_tracker=event_tracker,\\n    persona_repository=persona_repository,\\n    llm=llm_connector,\\n    timescale_tracker=timescale_tracker,\\n    memory_salesbot=memory_salesbot\\n)\\n\\nrule_base_service = RuleBaseBotService(\\n    prompt_builder=chatgpt_prompt,\\n    event_tracker=event_tracker,\\n    persona_repository=persona_repository,\\n    llm=llm_connector,\\n    timescale_tracker=timescale_tracker,\\n    memory_rule_bot=memory_rule_base_bot\\n)\\n\\nbot_universal_service = BotUniversalService(\\n    prompt_builder=chatgpt_prompt,\\n    event_tracker=event_tracker,\\n    persona_repository=persona_repository,\\n    llm=llm_connector,\\n    timescale_tracker=timescale_tracker\\n)\\n\\n\\ndef init_skill_update_service():\\n    sk_skill_updater = SKSkillUpdateService(\\n        sk_client=sk_client,\\n        redis_repo=redis_repo\\n    )\\n    return sk_skill_updater\\n\\n\\ndef init_general_function():\\n    general_function = GeneralFunction(\\n        sk_client=sk_client,\\n        state_cache_repo=StateCacheRepository(redis_conn=redis_conn),\\n        general_cache_repo=GeneralCacheRepository(redis_conn=redis_conn),\\n        gpt_client=gpt_client,\\n        intent_embedding=IntentEmbedding(),\\n        intent_classification_repo=IntentClassificationRepository(ES_VECTOR_DB_CONFIG)\\n    )\\n    return general_function\\n\\n\\ndef init_chatbot_agent():\\n    general_function = init_general_function()\\n\\n    doraemon_service = DoraemonBot(\\n        sk_client=sk_client,\\n        persona_repository=persona_repository,\\n        state_cache_repo=StateCacheRepository(redis_conn=redis_conn),\\n        general_function=general_function,\\n        middleware_feature_limit=MiddlewareFeatureLimit(balance_client=RgBalanceAPI()),\\n        middleware_balance=DoraBalanceMiddleWare(balance_client=RgBalanceAPI())\\n    )\\n\\n    onboarding_doraemon_service = OnboardingDoraemonBot(\\n        sk_client=sk_client,\\n        persona_repository=persona_repository,\\n        state_cache_repo=StateCacheRepository(redis_conn=redis_conn),\\n        general_function=general_function,\\n    )\\n\\n    learning_bot_service = LearningBotService(\\n        prompt_builder=chatgpt_prompt,\\n        event_tracker=event_tracker,\\n        persona_repository=persona_repository,\\n        discovery_service=chatbot_discovery,\\n        doraemon_service=doraemon_service,\\n        onboarding_dora_service=onboarding_doraemon_service,\\n        llm=llm_connector,\\n        timescale_tracker=timescale_tracker\\n    )\\n\\n    chatbot_agent = ChatbotAgent(\\n        salesbot_service=salesbot_service,\\n        rule_base_bot_service=rule_base_service,\\n        learning_bot_service=learning_bot_service,\\n        bot_universal_service=bot_universal_service,\\n        message_publisher=message_publisher,\\n        timescale_tracker=timescale_tracker\\n    )\\n    return chatbot_agent\\n\\n\\ndef init_dummy_general_function():\\n    general_function = DummyGeneralFunction(\\n        sk_client=sk_client_dummy,\\n        state_cache_repo=StateCacheRepository(redis_conn=redis_conn),\\n        general_cache_repo=GeneralCacheRepository(redis_conn=redis_conn),\\n        gpt_client=gpt_client,\\n        intent_embedding=IntentEmbedding()\\n    )\\n    return general_function\\n\\n\\ndef init_dummy_chatbot_agent():\\n    general_function = init_dummy_general_function()\\n\\n    doraemon_service = DoraemonBot(\\n        sk_client=sk_client_dummy,\\n        persona_repository=persona_repository,\\n        state_cache_repo=StateCacheRepository(redis_conn=redis_conn),\\n        general_function=general_function,\\n        middleware_feature_limit=MiddlewareFeatureLimit(balance_client=RgBalanceAPI()),\\n        middleware_balance=DoraBalanceMiddleWare(balance_client=RgBalanceAPI())\\n    )\\n\\n    onboarding_doraemon_service = OnboardingDoraemonBot(\\n        sk_client=sk_client_dummy,\\n        persona_repository=persona_repository,\\n        state_cache_repo=StateCacheRepository(redis_conn=redis_conn),\\n        general_function=general_function,\\n    )\\n\\n    learning_bot_service = LearningBotService(\\n        prompt_builder=chatgpt_prompt,\\n        event_tracker=event_tracker,\\n        persona_repository=persona_repository,\\n        discovery_service=chatbot_discovery,\\n        doraemon_service=doraemon_service,\\n        onboarding_dora_service=onboarding_doraemon_service,\\n        llm=llm_connector,\\n        timescale_tracker=timescale_tracker\\n    )\\n\\n    chatbot_agent = ChatbotAgent(\\n        salesbot_service=salesbot_service,\\n        rule_base_bot_service=rule_base_service,\\n        learning_bot_service=learning_bot_service,\\n        bot_universal_service=bot_universal_service,\\n        message_publisher=message_publisher_dummy,\\n        timescale_tracker=timescale_tracker\\n    )\\n    return chatbot_agent\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\container.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from fastapi import Request\\nfrom fastapi.applications import FastAPI\\nfrom fastapi.exceptions import RequestValidationError\\nfrom starlette.exceptions import HTTPException as StarletteHTTPException\\nfrom ds_chatbot.api.views import error_response\\nfrom ds_chatbot.core.service.exceptions import (\\n    BotReplyError, PersonaNotFoundError, PersonaDuplicateEntryError,\\n    PersonaStateValidationError, PersonaPlannerNotFoundError,\\n    SkillNotFoundError, LLMException, TenantIDNotFoundError)\\nfrom semantic_kernel.connectors.ai.ai_exception import AIException\\nfrom ds_chatbot.api.auth import AuthException\\nfrom ds_chatbot.core.service.exceptions import LimitChatException\\nimport logging\\n\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nasync def request_validation_handler(_: Request, error: RequestValidationError):\\n    validation_errors = [(\".\".join(str(x) for x in e[\"loc\"]), e[\"type\"])\\n                         for e in error.errors()]\\n    return error_response(error, 400, validation_errors)\\n\\n\\nasync def http_exception_handler(_, error: StarletteHTTPException):\\n    return error_response(error)\\n\\n\\nasync def bad_request_exception_handler(_, error: Exception):\\n    return error_response(error, 400)\\n\\n\\nasync def not_found_exception_handler(_, error: Exception):\\n    return error_response(error, 404)\\n\\n\\nasync def auth_exception_handler(_: Request, error: AuthException):\\n    return error_response(error, 401, [(\"Token\", error.message)])\\n\\n\\nasync def persona_not_found_exception_handler(_: Request, error: PersonaNotFoundError):\\n    logger.error(f\"Persona Not Found: {error.persona_id}\")\\n    return error_response(error, 404)\\n\\n\\nasync def tenant_id_not_found_exception_handler(_: Request, error: TenantIDNotFoundError):\\n    logger.error(f\"Tenant Id Not Found: {error.tenant_id}\")\\n    return error_response(error, 404)\\n\\n\\nasync def persona_planner_not_found_exception_handler(_: Request, error: PersonaPlannerNotFoundError):\\n    logger.error(f\"Persona Planner Not Found: {error.persona_id}\")\\n    return error_response(error, 404)\\n\\n\\nasync def skill_not_found_exception_handler(request: Request, error: Exception):\\n    logger.error(f\"Skill Not Found: {request}\")\\n    return error_response(error, 404)\\n\\n\\nasync def persona_state_validation_exception_handler(_, error: PersonaStateValidationError):\\n    return error_response(error, 400, [(\"PersonaStateValidationError\", error) for error in error.errors])\\n\\n\\nasync def ai_exception_handler(_, error):\\n    logger.error(f\"OpenAI API error with detail: {error}\")\\n    return error_response(error, 500)\\n\\n\\nasync def llm_exception_handler(_, error: LLMException):\\n    logger.error(f\"LLM API error with detail: platform: {error.platform}, message: {error.error_message}\")\\n    return error_response(error, 500)\\n\\n\\nasync def limit_chat_exception_handler(request: Request, error: Exception):\\n    request_body = await request.body()\\n    logger.error(f\"{error} - request_body: {request_body}\")\\n    return error_response(error, 401)\\n\\n\\ndef register_error_handlers(app: FastAPI) -> FastAPI:\\n    app.exception_handler(RequestValidationError)(request_validation_handler)\\n    app.exception_handler(StarletteHTTPException)(http_exception_handler)\\n    app.exception_handler(BotReplyError)(bad_request_exception_handler)\\n    app.exception_handler(PersonaNotFoundError)(persona_not_found_exception_handler)\\n    app.exception_handler(PersonaPlannerNotFoundError)(persona_planner_not_found_exception_handler)\\n    app.exception_handler(PersonaDuplicateEntryError)(\\n        bad_request_exception_handler)\\n    app.exception_handler(AuthException)(auth_exception_handler)\\n    app.exception_handler(PersonaStateValidationError)(\\n        persona_state_validation_exception_handler)\\n    app.exception_handler(AIException)(ai_exception_handler)\\n    app.exception_handler(TenantIDNotFoundError)(tenant_id_not_found_exception_handler)\\n    app.exception_handler(LLMException)(llm_exception_handler)\\n    app.exception_handler(LimitChatException)(limit_chat_exception_handler)\\n    app.exception_handler(SkillNotFoundError)(skill_not_found_exception_handler)\\n    return app\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\error_handlers.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from fastapi.applications import FastAPI\\nfrom ds_chatbot.api.routers.persona import db_conn\\nfrom ds_chatbot.api.container import db_chat_history_conn\\nfrom ds_chatbot.client.common.async_http import async_http_open, async_http_close\\n\\n\\nasync def startup() -> None:\\n    await async_http_open()\\n    await db_conn.connect()\\n    await db_chat_history_conn.connect()\\n\\n\\nasync def shutdown() -> None:\\n    await async_http_close()\\n    await db_conn.disconnect()\\n    await db_chat_history_conn.disconnect()\\n\\n\\ndef register_events(app: FastAPI) -> FastAPI:\\n    app.add_event_handler(\"startup\", startup)\\n    app.add_event_handler(\"shutdown\", shutdown)\\n    return app\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\events.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from fastapi.applications import FastAPI\\n\\nfrom ds_chatbot.api.routers import chatbot_chatgpt, health, product, persona, dummy_chatbot, semantic_kernel\\nfrom ds_chatbot.api.error_handlers import register_error_handlers\\nfrom ds_chatbot.api.events import register_events\\nfrom ds_chatbot.api.middleware import register_middlewares\\nfrom ds_chatbot.utils.utils import pipe\\n\\n\\ndef create_instance() -> FastAPI:\\n    return FastAPI()\\n\\n\\ndef init_database(app: FastAPI) -> FastAPI:\\n    return app\\n\\n\\ndef register_routers(app: FastAPI) -> FastAPI:\\n    app.include_router(chatbot_chatgpt.router)\\n    app.include_router(product.router)\\n    app.include_router(persona.router)\\n    app.include_router(dummy_chatbot.router)\\n    app.include_router(health.router)\\n    app.include_router(semantic_kernel.router)\\n    return app\\n\\n\\ndef init_app() -> FastAPI:\\n    app: FastAPI = pipe(\\n        create_instance(),\\n        init_database,\\n        register_events,\\n        register_middlewares,\\n        register_error_handlers,\\n        register_routers\\n    )\\n    return app\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\factory.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\nfrom typing import Callable\\n\\nfrom fastapi import Request, Response\\nfrom starlette.middleware.base import BaseHTTPMiddleware\\nfrom fastapi.applications import FastAPI\\nfrom ds_chatbot.api.views import error_response\\nimport time\\nfrom ds_chatbot.config import ROGU_MIDDLEWARE_CONFIG\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nclass RoguLoggerMiddleware(BaseHTTPMiddleware):\\n\\n    # ref: https://github.com/encode/starlette/issues/495\\n    async def _reset_receive(self, request, content):\\n        async def receive():\\n            return content\\n        request._receive = receive\\n\\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\\n        is_copy_request = ROGU_MIDDLEWARE_CONFIG.IS_COPY_REQUEST\\n        if is_copy_request:\\n            request_receive = await request.receive()\\n            await self._reset_receive(request, request_receive)\\n\\n        start_time = time.monotonic()\\n\\n        try:\\n            response = await call_next(request)\\n            processing_time = time.monotonic() - start_time\\n            response.headers[\"x-processing-time\"] = str(round(processing_time*1000, 2))\\n            return response\\n        except Exception as e:\\n            # catch any exception during performing request\\n            # and log the error along with the request body\\n            if is_copy_request:\\n                extra = {\"request_body\": request_receive[\"body\"], \"request_path\": request.url.path}\\n                logger.exception(e, extra=extra)\\n            else:\\n                logger.exception(e)\\n            return error_response(e)\\n\\n\\ndef register_middlewares(app: FastAPI) -> FastAPI:\\n    app.add_middleware(RoguLoggerMiddleware)\\n    return app\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\middleware.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\nimport re\\nimport http\\nimport json\\n\\nfrom typing import Dict, List, Optional, Type\\nfrom fastapi.responses import JSONResponse\\nfrom starlette.exceptions import HTTPException as StarletteHTTPException\\nfrom ds_chatbot.core.service.dto import ProductsResponseBody, ChatbotResponseBody, PersonaResponseBody\\nfrom ds_chatbot.core.entity import TypeResponse\\nfrom ds_chatbot.utils.utils import generate_uuid\\nfrom ds_chatbot.core.service.exceptions import BotReplyError, LimitChatException, LLMException\\nfrom semantic_kernel.connectors.ai.ai_exception import AIException\\nfrom ds_chatbot.utils.utils import generate_uuid\\nimport openai\\n\\n\\ndef learning_bot_non_streaming_response(response: ChatbotResponseBody):\\n    replies = []\\n    for list_body in response.replies:\\n        response_body = []\\n        for body in list_body:\\n            response_body.append(body.model_dump())\\n        replies.append(response_body)\\n    message_choices = []\\n    for row in response.message_choices:\\n        row_dict = row.dict()\\n        row_dict.pop(\"message_id\")\\n        message_choices.append(row_dict)\\n\\n    output = {\\n        \"uuid\": response.uuid,\\n        \"reply\": response.reply,\\n        \"replies\": replies,\\n        \"message_choices\": message_choices,\\n        \"type_response\": response.type_response,\\n        \"state\": response.state,\\n        \"label_object\": response.label_object,\\n        \"session_topic\": response.session_topic,\\n        \"salesbot_explanation\": response.salesbot_explanation\\n    }\\n\\n    return output\\n\\n\\nasync def learning_bot_streaming_response(response):\\n    async for row in response:\\n        replies = []\\n        for list_body in row.replies:\\n            response_body = []\\n            for body in list_body:\\n                response_body.append(body.dict())\\n            replies.append(response_body)\\n\\n        message_choices = []\\n        for msg_choice in row.message_choices:\\n            row_dict = msg_choice.dict()\\n            row_dict.pop(\"message_id\")\\n            message_choices.append(row_dict)\\n\\n        output = {\\n            \"data\": {\\n                \"data\": {\\n                    \"uuid\": row.uuid,\\n                    \"reply\": row.reply,\\n                    \"message_choices\": message_choices,\\n                    \"type_response\": row.type_response,\\n                    \"replies\": replies,\\n                    \"state\": row.state,\\n                    \"label_object\": row.label_object,\\n                    \"session_topic\": row.session_topic,\\n                    \"salesbot_explanation\": row.salesbot_explanation\\n                },\\n                \"status\": \"success\",\\n                \"message\": \"success\"\\n            }\\n        }\\n        yield json.dumps(output)\\n\\n\\nasync def learning_bot_http_response(response):\\n    async for row in response:\\n        replies = []\\n        for list_body in row.replies:\\n            response_body = []\\n            for body in list_body:\\n                response_body.append(body.dict())\\n            replies.append(response_body)\\n\\n        message_choices = []\\n        for msg_choice in row.message_choices:\\n            row_dict = msg_choice.dict()\\n            row_dict.pop(\"message_id\")\\n            message_choices.append(row_dict)\\n\\n        output = {\\n            \"uuid\": row.uuid,\\n            \"reply\": row.reply,\\n            \"replies\": replies,\\n            \"message_choices\": message_choices,\\n            \"type_response\": row.type_response,\\n            \"state\": row.state,\\n            \"label_object\": row.label_object,\\n            \"session_topic\": row.session_topic\\n        }\\n        yield output\\n\\n\\ndef learning_bot_response(response):\\n    return JSONResponse(\\n        dict(\\n            data=response,\\n            status=\"success\",\\n            message=\"success\"\\n        )\\n    )\\n\\n\\ndef static_learning_bot_response(request):\\n    output = ChatbotResponseBody(\\n        uuid=generate_uuid(),\\n        reply=\"\",\\n        type_response=TypeResponse.PUBLISH,\\n    )\\n    return output.dict()\\n\\n\\ndef product_response(response: ProductsResponseBody):\\n    return JSONResponse(\\n            dict(\\n                data={\\n                    \"uuid\": generate_uuid(),\\n                    \"reply\": response.reply_text,\\n                    \"products\": [x.dict() for x in response.products]\\n                },\\n                status=\"OK\",\\n                message=\"Success\",\\n            )\\n        )\\n\\n\\ndef persona_response(response: PersonaResponseBody):\\n    default_message_choices = []\\n    for row in response.message_choices:\\n        row_dict = row.dict()\\n        row_dict.pop(\"message_id\")\\n        default_message_choices.append(row_dict)\\n\\n    return JSONResponse(\\n        dict(\\n            data={\\n                \"uuid\": response.uuid,\\n                \"serial\": response.serial,\\n                \"persona\": response.persona,\\n                \"mode\": response.mode,\\n                \"initial_message\": response.initial_message,\\n                \"message_choices\": default_message_choices,\\n                \"tenant_id\": response.tenant_id,\\n                \"product_type\": response.product_type,\\n                \"is_rule_base\": response.is_rule_base\\n            },\\n            status=\"OK\",\\n            message=\"Success\"\\n        )\\n\\n    )\\n\\n\\ndef list_persona_response(response: List[dict]):\\n    return JSONResponse(\\n        dict(\\n            data=response,\\n            status=\"OK\",\\n            message=\"Success\"\\n        )\\n\\n    )\\n\\n\\ndef _camel_to_snake(name):\\n    name = re.sub(\\'(.)([A-Z][a-z]+)\\', r\\'\\\\1_\\\\2\\', name)\\n    return re.sub(\\'([a-z0-9])([A-Z])\\', r\\'\\\\1_\\\\2\\', name).upper()\\n\\n\\ndef error_response(error: Exception, code: int = 500, descriptions: Optional[List] = None):\\n    if descriptions is None:\\n        descriptions = []\\n\\n    status = http.HTTPStatus(code).name\\n\\n    if isinstance(error, StarletteHTTPException):\\n        name = error.detail.replace(\" \", \"\")\\n        code = error.status_code\\n    else:\\n        name = error.__class__.__name__\\n\\n    if isinstance(error, BotReplyError):\\n        error_message = [\\n                {\"field\": \"\", \"message\": str(error)}\\n            ]\\n    elif isinstance(error, AIException):\\n        if error.args[2] is not None:\\n            code = error.args[2].status_code\\n            message = str(error.args[2].body.get(\"message\", \"\"))\\n            error_field = _camel_to_snake(error.args[2].__class__.__name__)\\n            if code is None:\\n                code = 500\\n            status = http.HTTPStatus(code).name\\n\\n        else:\\n            message = error.args[1]\\n            error_field = _camel_to_snake(error._error_code.name)\\n            if error._error_code == AIException.ErrorCodes.InvalidRequest:\\n                code = 400\\n                status = http.HTTPStatus(code).name\\n                error_field = _camel_to_snake(openai.error.InvalidRequestError.__name__)\\n\\n        error_message = [\\n                {\"field\": error_field, \"message\": message}\\n            ]\\n\\n    elif isinstance(error, LLMException):\\n        code = error.error_code\\n        status = http.HTTPStatus(code).name\\n\\n        error_field = _camel_to_snake(error.platform)\\n        message = error.error_message\\n\\n        error_message = [\\n                {\"field\": error_field, \"message\": message}\\n        ]\\n\\n    elif isinstance(error, LimitChatException):\\n        error_message = [\\n            {\"field\": error.errors[\"field\"], \"message\": error.errors[\"message\"]}\\n        ]\\n\\n    else:\\n        error_message = [\\n                {\"field\": desc[0], \"message\": desc[1]} for desc in descriptions\\n            ]\\n    return JSONResponse(\\n        dict(\\n            status=status,\\n            error=_camel_to_snake(name),\\n            code=code,\\n            error_code=error_message,\\n            metadata={\"uuid\": generate_uuid()}\\n        ),\\n        status_code=code,\\n    )\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\views.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from ds_chatbot.api.factory import init_app\\n\\n\\napp = init_app()\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\__init__.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\nfrom fastapi.routing import APIRouter\\nfrom fastapi import Request, BackgroundTasks, Depends\\nfrom sse_starlette.sse import EventSourceResponse\\nfrom ds_chatbot.api.views import (\\n    learning_bot_response,\\n    learning_bot_non_streaming_response,\\n    learning_bot_streaming_response,\\n    learning_bot_http_response,\\n    static_learning_bot_response\\n)\\nfrom ds_chatbot.core.service.dto import LearningBotRequest\\nfrom ds_chatbot.api.container import init_chatbot_agent, message_duplicate_checker, timescale_tracker\\nfrom ds_chatbot.api.util.logging import log_request, log_streaming_request\\nfrom fastapi.responses import JSONResponse\\nfrom ds_chatbot.api.auth import Authenticate, Context\\n\\n\\nlogger = logging.getLogger(__name__)\\nrouter = APIRouter()\\nchatbot_agent = init_chatbot_agent()\\n\\n\\n@router.post(\"/chatbot/learning/send\")\\nasync def generate_text_endpoint(chatbot_request: LearningBotRequest, request: Request, background_task: BackgroundTasks):\\n    logger.info(f\"First entry; session_id: {chatbot_request.session_id}\" +\\n        f\" user_serial: {chatbot_request.user_serial}, request_msg_id: {chatbot_request.request_msg_id}\")\\n\\n    background_task.add_task(timescale_tracker.track_incoming_message, chatbot_request)\\n    duplicate = message_duplicate_checker.is_duplicate(chatbot_request.request_msg_id)\\n\\n    if duplicate:\\n        return JSONResponse(dict(status=\"Message Id Duplicate\"), status_code=409)\\n\\n    if chatbot_request.use_new_http:\\n        static_response = static_learning_bot_response(chatbot_request)\\n        background_task.add_task(chatbot_agent.run_background, chatbot_request)\\n        logger.info(f\"Success send response with request_message_id: {chatbot_request.request_msg_id} session_id: {chatbot_request.session_id}\")\\n        return learning_bot_response(static_response)\\n    else:\\n        raw_response = await chatbot_agent.run(chatbot_request)\\n        if chatbot_request.stream:\\n            response = learning_bot_streaming_response(raw_response)\\n            background_task.add_task(log_streaming_request, request, response)\\n            return EventSourceResponse(response)\\n        else:\\n            response = learning_bot_non_streaming_response(raw_response)\\n            background_task.add_task(log_request, request, learning_bot_response(response))\\n            return learning_bot_response(response)\\n\\n# TODO: Remove this endpoint if BE/FE provides a new platform for bulk testing\\n@router.post(\"/chatbot/learning/send_with_auth\")\\nasync def generate_text_endpoint(chatbot_request: LearningBotRequest, request: Request, background_task: BackgroundTasks, context: Context = Depends(Authenticate())):\\n    logger.info(f\"First entry; session_id: {chatbot_request.session_id}\" +\\n        f\" user_serial: {chatbot_request.user_serial}, request_msg_id: {chatbot_request.request_msg_id}\")\\n\\n    background_task.add_task(timescale_tracker.track_incoming_message, chatbot_request)\\n    duplicate = message_duplicate_checker.is_duplicate(chatbot_request.request_msg_id)\\n\\n    if duplicate:\\n        return JSONResponse(dict(status=\"Message Id Duplicate\"), status_code=409)\\n\\n    if chatbot_request.use_new_http:\\n        static_response = static_learning_bot_response(chatbot_request)\\n        background_task.add_task(chatbot_agent.run_background, chatbot_request)\\n        logger.info(f\"Success send response with request_message_id: {chatbot_request.request_msg_id} session_id: {chatbot_request.session_id}\")\\n        return learning_bot_response(static_response)\\n    else:\\n        raw_response = await chatbot_agent.run(chatbot_request)\\n        if chatbot_request.stream:\\n            response = learning_bot_streaming_response(raw_response)\\n            background_task.add_task(log_streaming_request, request, response)\\n            return EventSourceResponse(response)\\n        else:\\n            response = learning_bot_non_streaming_response(raw_response)\\n            background_task.add_task(log_request, request, learning_bot_response(response))\\n            return learning_bot_response(response)\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\chatbot_chatgpt.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\nfrom fastapi.routing import APIRouter\\nfrom fastapi import Request, BackgroundTasks\\nfrom sse_starlette.sse import EventSourceResponse\\nfrom ds_chatbot.api.views import (\\n    learning_bot_response,\\n    learning_bot_non_streaming_response,\\n    learning_bot_streaming_response,\\n    static_learning_bot_response\\n)\\nfrom ds_chatbot.api.util.logging import log_request, log_streaming_request\\nfrom ds_chatbot.core.service.dto import LearningBotRequest\\nfrom fastapi.responses import JSONResponse\\nfrom ds_chatbot.api.container import init_dummy_chatbot_agent, message_duplicate_checker, timescale_tracker\\n\\n\\nlogger = logging.getLogger(__name__)\\nchatbot_agent = init_dummy_chatbot_agent()\\nrouter = APIRouter()\\n\\n\\n@router.post(\"/chatbot/learning/send_dummy\")\\nasync def generate_text_endpoint(chatbot_request: LearningBotRequest, request: Request, background_task: BackgroundTasks):\\n    background_task.add_task(timescale_tracker.track_incoming_message, chatbot_request)\\n    duplicate = False\\n\\n    if duplicate:\\n        return JSONResponse(dict(status=\"Message Id Duplicate\"), status_code=409)\\n\\n    if chatbot_request.use_new_http:\\n        static_response = static_learning_bot_response(chatbot_request)\\n        background_task.add_task(chatbot_agent.run_background, chatbot_request)\\n        logger.info(f\"Success send response with request_message_id: {chatbot_request.request_msg_id} session_id: {chatbot_request.session_id}\")\\n        return learning_bot_response(static_response)\\n    else:\\n        raw_response = await chatbot_agent.run(chatbot_request)\\n        if chatbot_request.stream:\\n            response = learning_bot_streaming_response(raw_response)\\n            background_task.add_task(log_streaming_request, request, response)\\n            return EventSourceResponse(response)\\n        else:\\n            response = learning_bot_non_streaming_response(raw_response)\\n            background_task.add_task(log_request, request, learning_bot_response(response))\\n            return learning_bot_response(response)\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\dummy_chatbot.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from fastapi import Request\\nfrom fastapi.responses import JSONResponse\\nfrom fastapi.routing import APIRouter\\n\\nrouter = APIRouter()\\n\\n\\n@router.get(\"/_health\")\\nasync def health(request: Request):\\n    return JSONResponse(dict(status=\"OK\"), status_code=200)\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\health.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='from fastapi import Request, Depends, HTTPException\\nfrom fastapi.responses import JSONResponse\\nfrom fastapi.routing import APIRouter\\nfrom ds_chatbot.core.service.persona import PersonaService\\nfrom ds_chatbot.core.service.persona_state import PersonaStateService\\nfrom ds_chatbot.config import MYSQL_CONFIG, REDIS_CONFIG\\nfrom ds_chatbot.shared.repository import get_db_conn\\nfrom ds_chatbot.repository.redis.redis_repo import (\\n    create_redis_connection, RedisRepository\\n)\\n\\nfrom ds_chatbot.core.service.persona import PersonaService\\nfrom ds_chatbot.repository.persona import PersonaRepository\\nfrom ds_chatbot.core.service.dto import PostPersonaRequestData, PersonaStateRequest, PersonaListSelfService\\nfrom ds_chatbot.api.views import persona_response, list_persona_response\\nfrom typing import Optional\\nfrom ds_chatbot.api.auth import Authenticate, Context\\n\\nrouter = APIRouter()\\ndb_conn = get_db_conn(MYSQL_CONFIG)\\npersona_service = PersonaService(persona_repository=PersonaRepository(db_conn))\\n\\nredis_conn = create_redis_connection(REDIS_CONFIG)\\nredis_repo = RedisRepository(redis_conn)\\n\\npersona_state_service = PersonaStateService(redis_repo)\\n\\n\\n@router.post(\"/chatbot/persona\")\\nasync def create_persona(\\n    request: PostPersonaRequestData, context: Context = Depends(Authenticate(allowed_roles=[\"admin\"]))\\n):\\n    await persona_service.create_persona(request)\\n\\n    return JSONResponse(dict(status=\"OK\"), status_code=201)\\n\\n\\n@router.get(\"/chatbot/persona/{persona_serial}\")\\nasync def get_persona(persona_serial: str, context: Context = Depends(Authenticate())):\\n    result = await persona_service.get_persona_by_serial(persona_serial)\\n    response = persona_response(result)\\n\\n    return response\\n\\n\\n@router.put(\"/chatbot/persona/{persona_serial}\")\\nasync def update_persona(\\n    persona_serial: str,\\n    request: PostPersonaRequestData,\\n    context: Context = Depends(Authenticate(allowed_roles=[\"admin\"])),\\n):\\n    await persona_service.update_persona(persona_serial, request)\\n\\n    return JSONResponse(dict(status=\"OK\"), status_code=200)\\n\\n\\n@router.delete(\"/chatbot/persona/{persona_serial}\")\\nasync def delete_persona(\\n    persona_serial: str, context: Context = Depends(Authenticate(allowed_roles=[\"admin\"]))\\n):\\n    response = await persona_service.delete_persona(persona_serial)\\n\\n    return JSONResponse(dict(status=\"OK\"), status_code=200)\\n\\n\\n@router.get(\"/chatbot/personas\")\\nasync def get_persona(\\n    mode: Optional[str] = None,\\n    limit: Optional[int] = 5,\\n    page: Optional[int] = 1,\\n    context: Context = Depends(Authenticate(allowed_roles=[\"admin\"])),\\n):\\n    result = await persona_service.get_personas(mode, limit, page)\\n    response = list_persona_response(result)\\n\\n    return response\\n\\n\\n@router.get(\"/chatbot/personas-tenant\")\\nasync def get_persona_tenant_id(\\n    tenant_id: str,\\n    mode: Optional[str] = None,\\n    context: Context = Depends(Authenticate(allowed_roles=[\"admin\"])),\\n):\\n    result = await persona_service.get_personas_by_tenant_id(tenant_id, mode)\\n    response = list_persona_response(result)\\n\\n    return response\\n\\n\\n@router.post(\"/chatbot/persona/state\")\\nasync def save_persona_state(request: PersonaStateRequest, context: Context = Depends(Authenticate(allowed_roles=[\"admin\"]))):\\n    await persona_state_service.save_persona_state(request)\\n    return {\"status\": \"OK\"}\\n\\n\\n@router.post(\"/chatbot/persona/config_persona_list_salesbot\")\\nasync def save_persona_list_salesbot(request: PersonaListSelfService):\\n    if request.do_process == \"save\":\\n        status_process = await persona_state_service.save_persona_list_salesbot(request)\\n    elif request.do_process == \"delete\":\\n        status_process = await persona_state_service.delete_persona_list_salesbot(request)\\n    else:\\n        raise HTTPException(status_code=400, detail=\"Error: Invalid do_process value\")\\n\\n    if status_process:\\n        return JSONResponse(content={\"status\": \"OK\"}, status_code=200)\\n    else:\\n        raise HTTPException(status_code=400, detail=\"Error: There is on going proces, please wait\")\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\persona.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\n\\nfrom fastapi.routing import APIRouter\\n\\nfrom ds_chatbot.api.views import product_response\\nfrom ds_chatbot.core.service.dto import ProductsRequestBody\\nfrom ds_chatbot.repository.product import ProductAnswerRepository\\nfrom ds_chatbot.core.service.product import ProductAnswerService\\nfrom ds_chatbot.config import ES_CONFIG\\n\\nlogger = logging.getLogger(__name__)\\n\\nrouter = APIRouter()\\n\\nproduct_answer_service = ProductAnswerService(\\n    product_answer_repo=ProductAnswerRepository(ES_CONFIG)\\n)\\n\\n\\n@router.post(\"/chatbot/products\")\\nasync def product_list(request: ProductsRequestBody):\\n    response = await product_answer_service(request)\\n    return product_response(response)\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\product.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\n\\nfrom ds_chatbot.core.service.dto import UpdateSkillRequest\\nfrom fastapi.routing import APIRouter\\nfrom fastapi.responses import JSONResponse\\nfrom ds_chatbot.api.container import init_skill_update_service\\n\\n\\nrouter = APIRouter()\\nlogger = logging.getLogger(__name__)\\nsk_skill_updater = init_skill_update_service()\\n\\n\\n@router.get(\"/chatbot/skills\")\\nasync def get_all_skill():\\n    \"\"\"\\n    Get All Skill list from semantic kernel\\n    \"\"\"\\n\\n    # get all skill still fetch from semantic kernel folder\\n    response = await sk_skill_updater.get_all_skill()\\n    return JSONResponse(\\n        dict(\\n            data=response,\\n            status=\"success\",\\n            message=\"success\"\\n        )\\n    )\\n\\n\\n@router.get(\"/chatbot/skill/{skill_name}\")\\nasync def get_skill(skill_name: str, env: str):\\n    \"\"\"\\n    Get specific skill prompt and config from semantic kernel from redis\\n    \"\"\"\\n    response = await sk_skill_updater.get_skill(skill_name, env)\\n    return JSONResponse(\\n        dict(\\n            data=response,\\n            status=\"success\",\\n            message=\"success\"\\n        )\\n    )\\n\\n\\n@router.put(\"/chatbot/skill/{skill_name}\")\\nasync def update_skill(skill_name: str, request: UpdateSkillRequest, env: str):\\n    \"\"\"\\n    Update specific skill prompt and config from semantic kernel from user\\n    \"\"\"\\n    await sk_skill_updater.update_skill(skill_name, request, env)\\n\\n    return JSONResponse(dict(status=\"OK\"), status_code=200)\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\semantic_kernel.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\routers\\\\__init__.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\nfrom fastapi import Request, Response\\n\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nasync def log_request(request: Request, response: Response):\\n    try:\\n        request_body = await request.body()\\n    except Exception:\\n        request_body = \"-\"\\n\\n    extra = {\"request_body\": request_body, \"response_body\": response.body or \"-\"}\\n    message = \"Outgoing Message, metadata: {remote_address} {status_line} {status} processing_time={response_time}ms {referer} {user_agent}\".format(  # noqa: E501\\n        remote_address=f\"{request.client.host}:{request.client.port}\",\\n        status_line=\"%s %s %s\" % (request.method, request.url, \"-\"),\\n        status=response.status_code,\\n        response_time=response.headers.get(\"x-processing-time\", \"\"),\\n        referer=request.headers.get(\"referer\", \"-\"),\\n        user_agent=request.headers.get(\"user-agent\", \"-\"),\\n    )\\n    logger.info(message, extra=extra)\\n\\n\\nasync def log_streaming_request(request, response: Response):\\n    try:\\n        request_body = await request.body()\\n    except Exception:\\n        request_body = \"-\"\\n\\n    extra = {\"request_body\": request_body, \"response_body\": \"-\"}\\n    message = \"Outgoing Message, metadata: {remote_address} {status_line} {status} processing_time={response_time}ms {referer} {user_agent}\".format(  # noqa: E501\\n        remote_address=f\"{request.client.host}:{request.client.port}\",\\n        status_line=\"%s %s %s\" % (request.method, request.url, \"-\"),\\n        status=\"-\",\\n        response_time=\"-\",\\n        referer=request.headers.get(\"referer\", \"-\"),\\n        user_agent=request.headers.get(\"user-agent\", \"-\"),\\n    )\\n    logger.info(message, extra=extra)\\n', metadata={'source': 'D:\\\\project-ruang-guru\\\\Project_DS_Intern\\\\source\\\\rg-ds-chatbot-api\\\\ds_chatbot\\\\api\\\\util\\\\logging.py', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunkings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_splitter = RecursiveCharacterTextSplitter.from_language(language = Language.PYTHON,\n",
    "                                                             chunk_size = 2000,\n",
    "                                                             chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = documents_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge base (vector DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory='./data-gpt-3.5-1')\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm, memory_key = \"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":5}), memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Apakah ada bug pada kode yang diberikan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak, berdasarkan potongan kode yang diberikan, tidak terlihat adanya bug yang jelas.\n"
     ]
    }
   ],
   "source": [
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Apakah ada kode yang perlu di optimisasi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kode yang diberikan terlihat sudah cukup baik dan tidak memerlukan optimisasi yang signifikan. Kode tersebut sudah terstruktur dengan baik dan mudah dibaca. Jika ada bagian tertentu yang ingin dioptimalkan, itu mungkin lebih pada preferensi atau kebutuhan spesifik proyek yang bersangkutan.\n"
     ]
    }
   ],
   "source": [
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Kode yang diberikan terlihat sudah cukup baik dan tidak memerlukan '\n",
      " 'optimisasi yang signifikan. Kode tersebut sudah terstruktur dengan baik dan '\n",
      " 'mudah dibaca. Jika ada bagian tertentu yang ingin dioptimalkan, itu mungkin '\n",
      " 'lebih pada preferensi atau kebutuhan spesifik proyek yang bersangkutan.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
